{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from matplotlib import pyplot as plt\n",
    "from time import sleep\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.dates import date2num, num2date\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from typing import NamedTuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/XBTUSDC_1.csv', header=None,\n",
    "                 names=['time', 'open', 'high', 'low', 'close', 'volume', 'trades'])\n",
    "df.set_index('time', inplace=True)\n",
    "df.index = pd.DatetimeIndex(df.index * 1e+9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trader1:\n",
    "    # Bollinger: https://www.investopedia.com/trading/using-bollinger-bands-to-gauge-trends/#:~:text=Using%20the%20bands%20as%20overbought,have%20deviated%20from%20the%20mean.\n",
    "    def __init__(self, n_cycles, n_devs, qty, take_at=0.005, fee=0.0026):\n",
    "        # qty = quantity to trade at a time\n",
    "        # EMA = Closing price x multiplier + EMA (previous day) x (1-multiplier)\n",
    "        # \n",
    "        # BOLU=MA(TP,n)+m∗σ[TP,n]\n",
    "        # BOLD=MA(TP,n)−m∗σ[TP,n]\n",
    "        # where:\n",
    "        # BOLU=Upper Bollinger Band\n",
    "        # BOLD=Lower Bollinger Band\n",
    "        # MA=Moving average\n",
    "        # TP (typical price)=(High+Low+Close)÷3\n",
    "        # n=Number of cycles in smoothing period ... n_cycles\n",
    "        # m=Number of standard deviations ... n_devs\n",
    "        # σ[TP,n]=Standard Deviation over last n periods of TP\n",
    "        #\n",
    "        # take_at = take profit at p0 * (1 + someting% + 2*fee)\n",
    "        self.N = n_cycles\n",
    "        self.M = n_devs\n",
    "        self.qty = qty\n",
    "        self.take_at = take_at\n",
    "        self.fee = fee\n",
    "        self.prices = np.array([0.] * self.N)\n",
    "        \n",
    "        self.sma = None\n",
    "        self.upper = None\n",
    "        self.lower = None\n",
    "        self.var = None\n",
    "        self.std = None\n",
    "        self.open_price = None\n",
    "        self.profit_price = None\n",
    "        self.loss_price = None\n",
    "    \n",
    "        self.position = 0\n",
    "        self.trades = []\n",
    "        \n",
    "        self.warming_up = True\n",
    "        self.i = 0\n",
    "    \n",
    "    def update(self, cycle, ohlc: dict, price):\n",
    "        _, high, low, close = self._unpack(ohlc)\n",
    "\n",
    "        last_price = self.prices[self.i]\n",
    "        self.prices[self.i] = price\n",
    "        self.i += 1\n",
    "        if self.i == len(self.prices):\n",
    "            self.i = 0\n",
    "            if self.warming_up:\n",
    "                self.warming_up = False\n",
    "                self.sma = np.mean(self.prices)\n",
    "                self.var = np.var(self.prices)\n",
    "                self.std = math.sqrt(self.var)\n",
    "                self.upper = self.sma + self.M * self.std\n",
    "                self.lower = self.sma - self.M * self.std\n",
    "                return\n",
    "\n",
    "        if not self.warming_up:\n",
    "            old_sma = self.sma\n",
    "            self.sma += (price - last_price) / self.N\n",
    "            self.var += (price - self.sma + last_price - old_sma)*(price - last_price)/(self.N)\n",
    "            self.var = self.check_var(self.var)\n",
    "            self.std = math.sqrt(self.var)\n",
    "            self.upper = self.sma + self.M * self.std\n",
    "            self.lower = self.sma - self.M * self.std\n",
    "            \n",
    "    def check(self, x):\n",
    "        if np.abs(x) > 0.01:\n",
    "            raise\n",
    "    \n",
    "    def check_var(self, var):\n",
    "        if var < 0:\n",
    "            if abs(var) >= 1.e-4:\n",
    "                raise Exception(f'var was {var}')\n",
    "            return 0.\n",
    "        return var\n",
    "    \n",
    "    def trade(self) -> float:  # return number of shares to trade\n",
    "        if self.warming_up:\n",
    "            return None\n",
    "        price = self.prices[self.i]\n",
    "        # buy\n",
    "        if price < self.lower and self.position <= 0:\n",
    "            if self.position == 0:\n",
    "                self.open_price = price\n",
    "                self.profit_price = price + self.take_at + 2*self.fee\n",
    "                self.loss_price = price - (self.take_at + 2*self.fee)\n",
    "            self.position += self.qty\n",
    "            return self.qty\n",
    "    \n",
    "        # sell\n",
    "        if price > self.upper and self.position >= 0:\n",
    "            if self.position == 0:\n",
    "                self.open_price = price\n",
    "                self.loss_price = price + self.take_at + 2*self.fee\n",
    "                self.profit_price = price - (self.take_at + 2*self.fee)\n",
    "            self.position -= self.qty\n",
    "            return -self.qty\n",
    "        \n",
    "        # profit\n",
    "        if self.position > 0:\n",
    "            if not self.loss_price <= price <= self.profit_price:\n",
    "                self.position -= self.qty\n",
    "                return -self.qty\n",
    "        elif self.position < 0:\n",
    "            if not self.profit_price <= price <= self.loss_price:\n",
    "                self.position += self.qty\n",
    "                return +self.qty\n",
    "    \n",
    "    @staticmethod\n",
    "    def _unpack(ohlc: dict):\n",
    "        return ohlc['open'], ohlc['high'], ohlc['low'], ohlc['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DcatTrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model that assumes we have aggregated information from the future\n",
    "class DcatTrader:\n",
    "    def __init__(self, window, actual_prices, take_min, qty, fee):\n",
    "        self.y = self.get_y2(window, actual_prices)\n",
    "        self.i = -1\n",
    "        self.position = 0\n",
    "        self.entry_price = 0\n",
    "        self.price = 0\n",
    "        self.take_min = take_min\n",
    "        self.qty = qty\n",
    "        self.fee = fee\n",
    "        \n",
    "    def update(self, _, __, price):\n",
    "        self.i += 1\n",
    "        self.price = price\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def trade(self):\n",
    "        if np.isnan(self.y[self.i]):\n",
    "            return\n",
    "        \n",
    "        # effective pnl% in terms of return r:\n",
    "        #    pnl/(p0*|q|) = r*sign(q) - fee*(2+r)\n",
    "        #                 = r*(sign(q) - f) - 2*fee\n",
    "        \n",
    "        t = self.take_min\n",
    "        f = self.fee\n",
    "        if self.position == 0:\n",
    "            r = self.y[self.i]\n",
    "            \n",
    "            is_good_buy = r >= (t+2*f)/(1-f)\n",
    "            is_good_sell = r <= -(t+2*f)/(1+f)\n",
    "        else:\n",
    "            r = (self.price - self.entry_price)/self.entry_price\n",
    "            \n",
    "            is_good_buy = self.position < 0 and r <= -(t+2*f)/(1+f)\n",
    "            is_good_sell = self.position > 0 and r >= (t+2*f)/(1-f)\n",
    "            \n",
    "        if is_good_buy:\n",
    "            self.entry_price = self.price if self.position == 0 else np.nan\n",
    "            self.position += self.qty  \n",
    "            return self.qty\n",
    "        elif is_good_sell:\n",
    "            self.entry_price = self.price if self.position == 0 else np.nan\n",
    "            self.position -= self.qty \n",
    "            return -self.qty          \n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    def get_y2(self, w, prices):\n",
    "                \n",
    "        ma = prices.iloc[::-1].rolling(w).max()\n",
    "        mi = prices.iloc[::-1].rolling(w).min()\n",
    "        s = (ma + mi).iloc[::-1]\n",
    "        return (.5*(s - 2.*prices)/prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade(df, model):\n",
    "    # model needs to have .update(cycle, ohlc) and trade()\n",
    "    # return the trades\n",
    "\n",
    "    trades = pd.DataFrame(index=df.index)\n",
    "    trades['qty'] = [0.] * len(trades)\n",
    "    \n",
    "    for i, (cycle, ohlc) in enumerate(df.iterrows()):\n",
    "        model.update(cycle, ohlc, ohlc['close'])\n",
    "        qty = model.trade()\n",
    "        if qty:\n",
    "            trades.iloc[i] = qty\n",
    "    return trades\n",
    "\n",
    "def account(prices, trades, fee=0.0026):\n",
    "    #prices = df.open\n",
    "    volume = prices * trades.qty * (1 + np.sign(trades.qty) * fee)\n",
    "\n",
    "    last_price = prices.iloc[-1]\n",
    "    qty_to_liquidate = -trades.qty.sum()\n",
    "    last_volume = last_price * qty_to_liquidate * (1 + np.sign(qty_to_liquidate) * fee)\n",
    "\n",
    "    pnl = -(last_volume + volume.sum())\n",
    "    \n",
    "    return pnl\n",
    "\n",
    "def cycle_realized_pnl(prices, trades, fee=0.0026):\n",
    "    #prices = df.open.shift(-1, fill_value=df.open.iloc[-1])\n",
    "    volume = prices * trades.qty * (1 + np.sign(trades.qty) * fee)\n",
    "    \n",
    "    values = pd.DataFrame(index=prices.index, columns=['pnl', 'adjusted_pnl']).fillna(0.)\n",
    "    v = 0.\n",
    "    position = 0.\n",
    "    max_position = 0.\n",
    "    open_price = 0.\n",
    "    for i, qty in enumerate(trades.qty):\n",
    "        was_open = position != 0\n",
    "        \n",
    "        position = round(position + qty, 8)\n",
    "        max_position = max(abs(position), max_position)\n",
    "        v -= volume.iloc[i]\n",
    "        \n",
    "        if not was_open and position != 0:\n",
    "            open_price = prices[i]\n",
    "        \n",
    "        if position == 0:\n",
    "            if was_open:\n",
    "                market_pnl = max_position * abs(prices[i] - open_price)\n",
    "                #market_pnl -= fee * max_position * (prices[i] + open_price)\n",
    "                values.iloc[i] = (v, v - market_pnl)\n",
    "            v = 0\n",
    "            max_position = 0\n",
    "            \n",
    "    if position:\n",
    "        last_price = prices.iloc[-1]\n",
    "        assert np.isclose(position, trades.qty.sum()), f'position={position}, trades.qty.sum()={trades.qty.sum()}'\n",
    "        qty_to_liquidate = -position\n",
    "        last_volume = last_price * qty_to_liquidate * (1 + np.sign(qty_to_liquidate) * fee)\n",
    "        assert values.iloc[-1][0] == 0\n",
    "        \n",
    "        market_pnl = max_position * abs(prices[i] - open_price)\n",
    "        #market_pnl -= fee * max_position * (prices[i] + open_price)\n",
    "        values.iloc[i] = (-last_volume + v, -last_volume + v - market_pnl)\n",
    "        \n",
    "        #values.iloc[-1] = -last_volume + v\n",
    "    return values\n",
    "\n",
    "def robustness(pnls, prices):\n",
    "    # It should tell how much the model depends on the market\n",
    "    returns = (prices.shift(-1) - prices)/prices\n",
    "    idx = pnls != 0\n",
    "    a = pnls[idx][:-1].corr(prices[idx][:-1])\n",
    "    return 1 - a*a\n",
    "\n",
    "\n",
    "def sharpe(pnls):\n",
    "    return np.sum(pnls) / np.std(pnls)\n",
    "\n",
    "def test_account():\n",
    "    #df = pd.DataFrame({'open': [10,11,12,13,14]})\n",
    "    #prices = df['open'].shift(-1, fill_value=df.open.iloc[-1])\n",
    "    prices = pd.Series([11,12,13,14,14])\n",
    "    \n",
    "    trades = pd.DataFrame({'qty': [1,-1,1,0,0]})\n",
    "    fee = 1\n",
    "    a = cycle_realized_pnl(prices, trades, fee=fee).pnl.sum()\n",
    "    b = account(prices, trades, fee=fee)\n",
    "    assert a == b\n",
    "    assert a == -48.\n",
    "    c = cycle_realized_pnl(prices, trades, fee=fee).adjusted_pnl.sum()\n",
    "    assert c == -50., f'c = {c}'\n",
    "\n",
    "test_account()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = trade(df, Trader1(10, 2, 0.002))\n",
    "acc = cycle_realized_pnl(df, trades)\n",
    "sharpe(acc.pnl), sharpe(acc.adjusted_pnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = trade(df, DcatTrader(75, actual_prices=df.close,\n",
    "                              take_min=0.005, qty=0.002, fee=0.0026))\n",
    "acc = cycle_realized_pnl(df.close, trades)\n",
    "rob = robustness(acc.pnl, df.close)\n",
    "sharpe(acc.pnl), len(acc.pnl[acc.pnl < 0]), len(acc.pnl[acc.pnl > 0]), rob\n",
    "# (6058.5075476589045, -8191.272070021878), (33, 1103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.pnl[acc.pnl < 0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = -0.005\n",
    "fee = 0.003\n",
    "qty = -0.0002\n",
    "\n",
    "# pnl/(p0*|q|) = r*sign(q) - fee*(2+r)\n",
    "r*np.sign(qty) - fee*(2+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [30]:\n",
    "    fee = 0.0001 * i\n",
    "    print(fee, (0.005 + 2*fee)/(1-fee), -(0.005 + 2*fee)/(1+fee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.010967098703888336 - fee * (2 -0.010967098703888336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(8652.87 * (1-0) - 8609.40 * (1+0))*0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades.loc['2020-02-17 16:50:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.open['2020-02-17 16:50:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.merge(trades, df, left_index=True, right_index=True)\n",
    "a = pd.merge(a, acc, left_index=True, right_index=True)\n",
    "a = a[a.qty!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.query('time <= \"2020-01-21 18:58:00\" and time >= \"2020-01-21 03:21:00\"')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_realized_pnl(b.close, b, fee=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "\n",
    "def plot(df, trades):\n",
    "    # df columns = ['open', 'high', 'low', 'close', 'volume', 'trades']\n",
    "    # trades columns = ['qty']\n",
    "\n",
    "    buys = df.open[trades.qty > 0]\n",
    "    sells = df.open[trades.qty < 0]\n",
    "    pnls = cycle_realized_pnl(df, trades).pnl\n",
    "    pnls = pnls[pnls != 0]\n",
    "    pnls = pnls.cumsum()\n",
    "    \n",
    "    trace = go.Scatter(\n",
    "        x=df.index,\n",
    "        y=df['open'],\n",
    "        name='Tick'\n",
    "    )\n",
    "\n",
    "    trace2 = go.Scatter(\n",
    "        x=buys.index,\n",
    "        y=buys,\n",
    "        #text=buys['order_id'],\n",
    "        #hoverinfo='text',\n",
    "        name='Buy',\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color='rgba(182, 255, 193, .9)',\n",
    "            line=dict(\n",
    "                width=2,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    trace3 = go.Scatter(\n",
    "        x=sells.index,\n",
    "        y=sells,\n",
    "        #text=sells['order_id'],\n",
    "        #hoverinfo='text',\n",
    "        name='Sell',\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=7,\n",
    "            color='rgba(255, 182, 193, .9)',\n",
    "            line=dict(\n",
    "                width=1,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    trace4 = go.Scatter(\n",
    "        x=pnls.index,\n",
    "        y=pnls,\n",
    "        name='P&L',\n",
    "        mode='lines+markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color='rgba(193, 182, 255, .9)',\n",
    "            line=dict(\n",
    "                width=1,\n",
    "            )\n",
    "        ),\n",
    "        yaxis='y2'\n",
    "    )\n",
    "    \n",
    "    data = [trace, trace2, trace3, trace4]\n",
    "    layout = go.Layout(\n",
    "        title='Trading log',\n",
    "        yaxis=dict(\n",
    "            title='Price'\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='BTC',\n",
    "            titlefont=dict(\n",
    "                color='rgb(148, 103, 189)'\n",
    "            ),\n",
    "            tickfont=dict(\n",
    "                color='rgb(148, 103, 189)'\n",
    "            ),\n",
    "            overlaying='y',\n",
    "            side='right'\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=False\n",
    "            )\n",
    "        ),\n",
    "        xaxis2=dict()\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    offline.plot(fig, auto_open=True, filename=os.path.join('/Users/felipe/crypto/bitme2', 'results_plot.html'))\n",
    "    # offline.iplot(fig)  #\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df, trades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/XBTUSDC_1.csv', header=None,\n",
    "                     names=['time', 'open', 'high', 'low', 'close', 'volume', 'trades'])\n",
    "df = df.set_index('time')\n",
    "df.index = pd.DatetimeIndex(df.index * 1e+9)\n",
    "#df = df.reindex(index=pd.date_range(df.index[0], df.index[-1],\n",
    "#                        freq=pd.Timedelta('00:01:00')), method='ffill', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of returns for research is different:\n",
    "returns = (df.close - df.open) / df.open\n",
    "prices = df.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y definition (it's not return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(w, prices):\n",
    "    ma = prices.iloc[::-1].rolling(w).max()\n",
    "    mi = prices.iloc[::-1].rolling(w).min()\n",
    "    s = (ma + mi).iloc[::-1]\n",
    "    return (.5*(s - 2.*prices)/prices).shift(-1)\n",
    "\n",
    "def get_lagged_y(w, prices):\n",
    "    ma = prices.rolling(w).max()\n",
    "    mi = prices.rolling(w).min()\n",
    "    s = (ma + mi)\n",
    "    return (.5*(s - 2.*prices)/prices)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## volatility per interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volatility(w, prices):\n",
    "    # This is not the standard volatility definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_std = {}\n",
    "for interval in (2, 5, 30, 60, 120, 300, 24*60, 7*24*60):\n",
    "    prices_mean = prices.rolling(interval, center=True).mean()\n",
    "    interval_std[interval] = ((prices - prices_mean)/prices_mean).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30/61000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.iloc[-100:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conclusion: they are all about the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be the interval that the lagged Y predicts Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cost and get_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(s, threshold):\n",
    "    s[s.abs() < threshold] = np.nan\n",
    "\n",
    "# Cost function\n",
    "def cost(prices, returns):\n",
    "   \n",
    "    def _helper(args):\n",
    "        lookback, lookahead = (int(i) for i in args)\n",
    "        if lookback <= 0 or lookahead <= 0:\n",
    "            return float('inf')\n",
    "        left = get_lagged_y(lookback, prices)\n",
    "        y = get_y(lookahead, prices)\n",
    "        #return -(left.corr(y)**2)\n",
    "        return -left.corr(-y)\n",
    "    return _helper\n",
    "\n",
    "def incremental_ewm(returns, lookback):\n",
    "    assert lookback > 1\n",
    "    d = {}\n",
    "    for i in range(2, lookback+1):\n",
    "        d[f'mean_ret{i}'] = returns.rolling(i).mean()\n",
    "    return d\n",
    "\n",
    "# features\n",
    "def get_x_y(prices, returns, lookback, lookahead):\n",
    "    lag_y = get_lagged_y(lookback, prices)\n",
    "    return pd.DataFrame({\n",
    "        #'mean_ret': returns.rolling(lookback).mean(),\n",
    "        'mean_ret1': returns,\n",
    "        **incremental_ewm(returns, lookback),\n",
    "        #'dmean': returns.diff().rolling(lookback).mean(),\n",
    "        #'d2mean': returns.diff().diff().rolling(lookback).mean(),\n",
    "        #'volatility': returns.rolling(lookback).std(),\n",
    "        #'lagged_y': lag_y,\n",
    "        #'sum_y': lag_y.cumsum(),\n",
    "        #'min': returns.rolling(lookback).min(),\n",
    "        #'max': returns.rolling(lookback).max(),\n",
    "        #'ewm': returns.ewm(span=lookback).mean(),\n",
    "        #'acce': returns.diff().ewm(span=lookback).mean(),\n",
    "        'y': get_y(lookahead, prices),\n",
    "    }, index=returns.index).dropna().astype(float)\n",
    "\n",
    "def get_acceleration(prices, returns, lookback, lookahead):\n",
    "    lag_y = get_lagged_y(lookback, prices)\n",
    "    y = get_y(lookahead, prices)\n",
    "    return pd.DataFrame({\n",
    "        #'ewm': returns.ewm(span=lookback).mean(),\n",
    "        'ewm': returns.rolling(lookback).sum()* (-0.08263353),\n",
    "        'y': y\n",
    "    }, index=returns.index)\n",
    "\n",
    "# cost function\n",
    "def get_acc_cost(prices, returns, lookback, lookahead, threshold=5e-3):\n",
    "    a = get_acceleration(prices, returns, lookback, lookahead).dropna()\n",
    "    original_len = len(a)\n",
    "    #apply_threshold(a['ewm'], threshold)\n",
    "    apply_threshold(a['y'], threshold)\n",
    "    a = a.dropna()\n",
    "    return (a['ewm'].corr(a['y'])) *1# (len(a)/ original_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i in range(25):\n",
    "    lookback = int((i+2)**(1.5)) or int((i+2)**(2.1))\n",
    "    for j in range(i):\n",
    "        lookahead = int((i+2)**(1.5)) or int((j+2)**(2.1))\n",
    "    #a = get_acceleration(prices, returns, lookback, 10)\n",
    "        results[(lookback, lookahead)] = get_acc_cost(prices, returns, lookback, lookahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results.items(), key=lambda x: results[x[0]], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_cost(prices, returns, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_acceleration(prices, returns, 125, 75)\n",
    "apply_threshold(a['ewm'], 1e-3)\n",
    "a.dropna().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best ewm span: 6200 with 72%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optmize with scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [150, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(cost(prices, returns), x0, method='nelder-mead',\n",
    "               options={'xatol': 1e-8, 'disp': True})\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost(prices, returns)([2000, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "args = []\n",
    "for lookback in range(50,101):\n",
    "    for lookahead in range(50,101):\n",
    "        args.append((lookback, lookahead))\n",
    "for i in trange(len(args)):\n",
    "    results[args[i]] = cost(returns)( args[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results.items(), key=lambda x: results[x[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: 75 mins lookback sum predicts 75 forward with 58% confident"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_x_y(prices, returns, 30, 30).dropna()\n",
    "y_train = X_train[['y']]\n",
    "X_train = X_train.drop('y', axis=1)\n",
    "\n",
    "train_size = int(0.80 * len(X_train))\n",
    "test_size = len(X_train) - train_size\n",
    "\n",
    "X_test = X_train.iloc[train_size:-1]\n",
    "y_test = y_train.iloc[train_size:-1]\n",
    "\n",
    "X_train = X_train.iloc[:train_size]\n",
    "y_train = y_train.iloc[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X_train, y_train)\n",
    "print(regr.coef_)\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_sign(s):\n",
    "    s = s.copy()\n",
    "    s[s < 0] = -1\n",
    "    s[s > 0] = 1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_x_y(prices, returns, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, feature_name in enumerate(X.columns):\n",
    "#for index, feature_name in enumerate(['sum']):\n",
    "    if feature_name != 'z':\n",
    "        plt.figure()\n",
    "        plt.scatter(X.iloc[:, index], X.y) \n",
    "        plt.xlabel(feature_name)\n",
    "        plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#data = pd.read_csv(\"D://Blogs//train.csv\")\n",
    "#X = data.iloc[:,0:20]  #independent columns\n",
    "#y = data.iloc[:,-1]    #target column i.e price range\n",
    "#get correlations of each features in dataset\n",
    "corrmat = X.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(10,7))\n",
    "#plot heat map\n",
    "g=sns.heatmap(X[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in X.columns:\n",
    "    if feature != 'y':\n",
    "        z = ((X[feature] - X.y).abs()/X.y.abs())\n",
    "        X1 = X[[feature, 'y']][z < 0.2]\n",
    "        X2 = X[[feature, 'y']][z >= 0.2]\n",
    "        plt.figure()\n",
    "        plt.scatter(X2.loc[:, feature], X2.y) \n",
    "        plt.scatter(X1.loc[:, feature], X1.y) \n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_x_y(prices, returns, 30, 30)\n",
    "x = regr.predict(X[[f for f in X.columns if f != 'y']].values)[:,0]\n",
    "#x = X[[f for f in X.columns if f != 'y']].dot([-3.32801942,  0.04858423,  0.02541414])\n",
    "x = pd.DataFrame({'y_pred': x, 'y': X.y}, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excess_tol = 0.00\n",
    "good_buy = (x.y_pred > 0) & (x.y > 0) & (x.y_pred <= x.y + excess_tol)\n",
    "good_sell = (x.y_pred < 0) & (x.y < 0) & (x.y_pred <= x.y - excess_tol)\n",
    "good = good_buy | good_sell\n",
    "#good = good_sell\n",
    "\n",
    "X1 = x[good]\n",
    "X2 = x[~good]\n",
    "plt.figure()\n",
    "plt.scatter(X2.y_pred, X2.y) \n",
    "plt.scatter(X1.y_pred, X1.y) \n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x.y_pred > 0].y_pred.corr(x[x.y_pred > 0].y),\\\n",
    "x[x.y_pred < 0].y_pred.corr(x[x.y_pred < 0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_sign(x[x.y_pred > 0].y_pred).corr(pd_sign(x[x.y_pred > 0].y)),\\\n",
    "pd_sign(x[x.y_pred < 0].y_pred).corr(pd_sign(x[x.y_pred < 0].y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_sign(x):\n",
    "    return pd.Series(np.sign(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_sign(x[x.y_pred > 0].y_pred).corr(pd_sign(x[x.y_pred > 0].y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr(pd_sign(x[x.y_pred > 0].y_pred),\n",
    "     pd_sign(x[x.y_pred > 0].y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(a, b):\n",
    "    a = a-a.mean()\n",
    "    b = b-b.mean()\n",
    "    return a.dot(b)#/np.sqrt((a.dot(a) * b.dot(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd_sign(x[x.y_pred > 0].y_pred)\n",
    "b = pd_sign(x[x.y_pred > 0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dot(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dot(b) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x[x.y_pred > 0].y > 0).sum()/len(a),\\\n",
    "(x[x.y_pred > 0].y <= 0).sum()/len(a),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try features with get_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, datasets, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_x_y(prices, returns, 30, 30).dropna()\n",
    "y_train = X_train[['y']]\n",
    "X_train = X_train.drop('y', axis=1)\n",
    "\n",
    "good_buys = y_train.transform(lambda x: x.transform(lambda z: 1 if z >= 0.01 else 0))\n",
    "good_sells = y_train.transform(lambda x: x.transform(lambda z: 1 if z <= -0.01 else 0))\n",
    "y_train = pd.DataFrame({'good_buys': good_buys.y, 'good_sells': good_sells.y},\n",
    "                      index=y_train.index)\n",
    "\n",
    "train_size = int(0.80 * len(X_train))\n",
    "test_size = len(X_train) - train_size\n",
    "\n",
    "X_test = X_train.iloc[train_size:-1]\n",
    "y_test = y_train.iloc[train_size:-1]\n",
    "\n",
    "X_train = X_train.iloc[:train_size]\n",
    "y_train = y_train.iloc[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('%s: %s' %\n",
    "      (KNeighborsClassifier.__name__, metrics.f1_score(y_test, y_pred, average=\"macro\")))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum(), (y_pred[:,0].sum(), y_pred[:,1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true positive\n",
    "y_test.good_buys[y_pred[:,0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the quality of the prediction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a pair (y_pred, y), create a classifier for y_pred with good or bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_x_y(prices, returns, 30, 30)\n",
    "x = regr.predict(X[[f for f in X.columns if f != 'y']].values)[:,0]\n",
    "#x = X[[f for f in X.columns if f != 'y']].dot([-3.32801942,  0.04858423,  0.02541414])\n",
    "x = pd.DataFrame({'y_pred': x, 'y': X.y}, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X.values, y.values,\n",
    "                            test_size=0.25)\n",
    "\n",
    "for Model in [GaussianNB, KNeighborsClassifier, LinearSVC]:\n",
    "    clf = Model().fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('%s: %s' %\n",
    "          (Model.__name__, metrics.f1_score(y_test, y_pred, average=\"macro\")))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [make_moons(noise=0.3, random_state=0)]\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def segments_fit(prices, count, start=pd.Timestamp.min, end=pd.Timestamp.max):\n",
    "    X = date2num(prices[start:end].index)\n",
    "    Y = prices[start:end].values\n",
    "    \n",
    "    xmin = X.min()\n",
    "    xmax = X.max()\n",
    "\n",
    "    seg = np.full(count - 1, (xmax - xmin) / count)\n",
    "\n",
    "    px_init = np.r_[np.r_[xmin, seg].cumsum(), xmax]\n",
    "    py_init = np.array([Y[np.abs(X - x) < (xmax - xmin) * 0.01].mean() for x in px_init])\n",
    "\n",
    "    def func(p):\n",
    "        seg = p[:count - 1]\n",
    "        py = p[count - 1:]\n",
    "        px = np.r_[np.r_[xmin, seg].cumsum(), xmax]\n",
    "        return px, py\n",
    "\n",
    "    def err(p):\n",
    "        px, py = func(p)\n",
    "        Y2 = np.interp(X, px, py)\n",
    "        return np.mean((Y - Y2)**2)\n",
    "\n",
    "    r = optimize.minimize(err, x0=np.r_[seg, py_init], method='Nelder-Mead')\n",
    "    return *func(r.x), np.sqrt(r.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coeffs = np.polyfit(date2num(df.close.index), df.close.values, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.polyfit(date2num(df.close.index), df.close.values, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.poly1d(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(p(date2num(df.close.index)), index=date2num(df.close.index)).plot()\n",
    "df.close.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.normal(3, 1, 100)\n",
    "y = np.random.normal(1, 1, 100)\n",
    "\n",
    "xedges = [0, 1, 1.5, 3, 5]\n",
    "yedges = [0, 2, 3, 4, 6]\n",
    "\n",
    "H, xedges, yedges = np.histogram2d(x, y, bins=(xedges, yedges))\n",
    "\n",
    "x2 = np.random.normal(3, 1, 100)\n",
    "y2 = np.random.normal(1, 1, 100)\n",
    "\n",
    "H += np.histogram2d(x2, y2, bins=(xedges, yedges))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most frequent max-min per period\n",
    "most_freq = {}\n",
    "for i in (5, 15, 100, 360, 1440):\n",
    "    a[f'var_{i}'] = (a.price.rolling(pd.Timedelta(f'{i}m')).max()\n",
    "                     - a.price.rolling(pd.Timedelta(f'{i}m')).min()) / a.price\n",
    "    count, x = np.histogram(a[f'var_{i}'].dropna(), bins=30)\n",
    "    k = np.argmax(count)\n",
    "    most_freq[i] = x[k], x[k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.polyfit(date2num(df.close[0:1]), df.close[0:1].values, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2num(pd.Timestamp('20150505'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = df.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "last_i = 0\n",
    "err = 0.01\n",
    "slope = np.zeros(len(prices))\n",
    "running_slope = np.zeros(len(prices))\n",
    "z = np.zeros(len(prices))\n",
    "running_z = np.zeros(len(prices))\n",
    "slope_return = np.zeros(len(prices))\n",
    "\n",
    "meanX = date2num(prices.index[0])\n",
    "meanY = prices.iloc[0]\n",
    "n = 1\n",
    "varX = covXY = a = b = 0\n",
    "z[0] = meanY\n",
    "running_z[0] = meanY\n",
    "\n",
    "for i in range(1, len(prices)):\n",
    "    x = date2num(prices.index[i])\n",
    "    y = prices.iloc[i]\n",
    "    \n",
    "    fit_well = abs(a * x + b - y)/y <= err\n",
    "    \n",
    "    if not fit_well:\n",
    "        z[last_i:i] = np.poly1d((a,b))(date2num(prices.index[last_i:i]))\n",
    "        slope[last_i:i] = np.ones(i-last_i) * running_slope[i-1]\n",
    "        slope_return[last_i:i] = (running_z[i-1] - running_z[last_i]) / running_z[last_i]\n",
    "        last_i = i\n",
    "        meanX = date2num(prices.index[i-1])\n",
    "        meanY = prices.iloc[i-1]\n",
    "        n = 1\n",
    "        varX = covXY = a = b = 0\n",
    "    \n",
    "    n += 1\n",
    "    dx = x - meanX\n",
    "    dy = y - meanY\n",
    "    varX += (((n-1)/n)*dx*dx - varX)/n\n",
    "    covXY += (((n-1)/n)*dx*dy - covXY)/n\n",
    "    meanX += dx/n\n",
    "    meanY += dy/n\n",
    "\n",
    "    a = covXY/varX\n",
    "    b = meanY - a*meanX\n",
    "            \n",
    "    running_slope[i] = a\n",
    "    running_z[i] = a * x + b\n",
    "\n",
    "z[last_i:] = np.poly1d((a,b))(date2num(prices.index[last_i:]))\n",
    "slope[last_i:] = np.ones(len(prices)-last_i) * running_slope[-1]\n",
    "slope_return[last_i:] = (running_z[-1] - running_z[last_i]) / running_z[last_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({'prices': df.close,\n",
    "                  'z': z,\n",
    "                  'running_z': running_z,\n",
    "                  'slope': np.arctan(slope/10000) * 2/np.pi,\n",
    "                  'running_slope': np.arctan(running_slope/10000) * 2/np.pi,\n",
    "                  'slope_return': slope_return})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.slope_return.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[['prices', 'z', 'running_z']].iloc[-500:].plot(figsize=(14, 8))\n",
    "#a['slope'].apply(np.log).iloc[-1000:].plot(figsize=(14, 4))\n",
    "#(a[['slope']]*0).plot(figsize=(14, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[['slope', 'running_slope']].iloc[-1000:].plot(style='.-', figsize=(14, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[a.slope.values != a.slope.shift(-1)][['slope', 'slope_return']].copy()\n",
    "b['time'] = b.index\n",
    "b['duration'] = (b.time - b.time.shift()).dt.seconds / 60\n",
    "b = b.dropna()\n",
    "b.duration = b.duration.astype(int)\n",
    "b.slope_return = b.slope_return.abs() >= 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_bins = [-.9, -.5, 0, .5, .9]\n",
    "duration_bins = np.linspace(20, 200, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['slope_bin'] = pd.cut(b.slope, slope_bins, include_lowest=True)\n",
    "b['duration_bin'] = pd.cut(b.duration, duration_bins, include_lowest=True)\n",
    "b = b.dropna()\n",
    "b['bin'] = list(zip(b['slope_bin'], b['duration_bin'], b['slope_return']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = sorted(b.bin.unique())\n",
    "states = pd.MultiIndex.from_tuples(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.DataFrame(np.zeros([len(states), len(states)]).astype(int), index=states, columns=states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(b)):\n",
    "    s1 = b.bin.iloc[i-1]\n",
    "    s2 = b.bin.iloc[i]\n",
    "    m.loc[s1, s2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.groupby('bin').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m.div(m.sum(axis=1), axis=0) * 100).astype(int).style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## window drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = df.close.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_out(prices, quantile=1e-4) -> None:\n",
    "    d2 = prices.shift(-1) - 2*prices + prices.shift(1)\n",
    "    q1 = d2.quantile(quantile)\n",
    "    q2 = d2.quantile(1-quantile)\n",
    "    prices[d2 < q1] = (prices.shift(-1) + prices.shift(1) - q1)/2\n",
    "    prices[d2 > q2] = (prices.shift(-1) + prices.shift(1) - q2)/2\n",
    "\n",
    "smooth_out(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_duration(df) -> None:\n",
    "    df['time'] = df.index\n",
    "    df['duration'] = (df.time - df.time.shift()).dt.seconds\n",
    "    df.dropna(inplace=True)\n",
    "    df['duration'] = df['duration'].astype(int) // 60\n",
    "    del df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_log_prices(log_prices: pd.Series, increment) -> pd.Series:\n",
    "    # Essentially disregard price movements lower than increment\n",
    "    x = np.zeros(len(log_prices))\n",
    "    y = log_prices.values\n",
    "    last_p = y[0]\n",
    "    for i, p in enumerate(y):\n",
    "        if abs(p - last_p) >= increment:\n",
    "            x[i] = p\n",
    "            last_p = p\n",
    "        else:\n",
    "            x[i] = last_p\n",
    "    x = pd.Series(x, index=log_prices.index)\n",
    "    x.name = log_prices.name\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend(prices, increment=0.01):\n",
    "    # Return aggregated-discretized-log prices\n",
    "    \n",
    "    log_p = prices.apply(np.log)\n",
    "    trend = discretize_log_prices(log_p, increment)\n",
    "    trend.name = 'price'\n",
    "    trend = trend.to_frame()\n",
    "    trend = trend.dropna()\n",
    "    \n",
    "    trend['return'] = trend['price'].diff()\n",
    "    trend.dropna(inplace=True)\n",
    "    trend['trend'] = np.sign(trend['return'].values)\n",
    "    # Remove consecutive same trend. Shift(-1) to keep the last\n",
    "    trend = trend[trend.trend.values != trend.trend.shift(-1).values]\n",
    "    # We have to calculate return again, because we removed elements\n",
    "    trend['return'] = trend['price'].diff()\n",
    "    trend.dropna(inplace=True)\n",
    "    \n",
    "    add_duration(trend)\n",
    "    \n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pattern_label(trend, max_return, increment_return, label_type: str) -> None:\n",
    "    # Add predictor/response labels\n",
    "    # Predictor: the bucketized return\n",
    "    # Response: -increment_return, +increment_return, or 0\n",
    "    \n",
    "    # We multiply by 1e3 to avoid rounding problems\n",
    "    labels = np.arange(0, int(max_return*1e3) + 1, int(increment_return*1e3))/1e3\n",
    "    labels = np.r_[-labels[-1:0:-1], labels]\n",
    "\n",
    "    cut = np.r_[labels[:len(labels)//2], labels[len(labels)//2 + 1:]]\n",
    "    # This is to not include the lower bond for negative numbers\n",
    "    cut[cut < 0] += 1e-10\n",
    "\n",
    "    assert len(cut)+1 == len(labels)\n",
    "\n",
    "    t = np.digitize(trend['return'], cut)\n",
    "    trend[label_type] = labels[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "#@dataclass\n",
    "class Score:#(NamedTuple):\n",
    "    freq: float\n",
    "    num: int\n",
    "    predictor: list\n",
    "    response: float\n",
    "    apy: float = 0\n",
    "    \n",
    "    def __init__(self, freq: float, num: int, predictor: list, response: float, apy: float=0.):\n",
    "        self.freq = round(freq, 2)\n",
    "        self.num = num\n",
    "        self.predictor = predictor\n",
    "        self.response = round(response, 2)\n",
    "        self.apy = round(apy, 2)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return (f'Score(apy={self.apy}, freq={self.freq}, num={self.num},'\n",
    "                f'predictor={self.predictor}, response={self.response})')\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return (self.apy, self.freq, self.num) < (other.apy, other.freq, other.num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_scores(trend, N, threshold) -> 'score, pattern':\n",
    "    # N number of elements in the pattern\n",
    "    # 0 < threshold < 1, score which the pattern is considered good\n",
    "    # pattern = vector of predictor_label + response_label\n",
    "    \n",
    "    m = defaultdict(int)\n",
    "    \n",
    "    def f(s):\n",
    "        v = trend.loc[s.index[-1], 'response_label']\n",
    "        m[tuple(s.values[:-1]) + (v,)] += 1\n",
    "        return 0.\n",
    "    \n",
    "    _ = trend.rolling(N)['predictor_label'].apply(f)\n",
    "    \n",
    "    predictors = Counter(i[:len(i)-1] for i in m)\n",
    "    \n",
    "    def score(p):\n",
    "        matches = {i:j for i,j in m.items() if p == i[:len(p)]}\n",
    "        # We add +1 and +2 as a technique to avoid 100%, which is unrealistic\n",
    "        score_ = (max(matches.values()) + 1) / (sum(matches.values()) + 2)\n",
    "        best = max(matches, key=lambda k: matches[k])\n",
    "        s = Score(freq=score_, num=matches[best], predictor=p, response=best[-1])\n",
    "        return s\n",
    "    \n",
    "    scores = sorted((score(p) for p in predictors), reverse=True)\n",
    "    scores = [i for i in scores if i.freq >= threshold]\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scores(best_scores, filter_score=None):\n",
    "    best_scores = list(best_scores)\n",
    "    \n",
    "    to_remove = []\n",
    "    for i, s1 in enumerate(best_scores):\n",
    "        b = s1.predictor\n",
    "        for j, s2 in enumerate(best_scores):\n",
    "            b2 = s2.predictor\n",
    "            if len(b) > len(b2) and b2 == b[len(b)-len(b2):]:\n",
    "                #print(f'Removing {b}, keeping {b2}')\n",
    "                to_remove.append(i)\n",
    "                break\n",
    "    \n",
    "    for j in reversed(sorted(to_remove)):\n",
    "        del best_scores[j]\n",
    "    to_remove.clear()\n",
    "    best_scores = list(reversed(sorted(best_scores)))\n",
    "    \n",
    "    if filter_score:\n",
    "        best_scores = [i for i in best_scores if not filter_score(i)]\n",
    "    \n",
    "    return best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_multiple_scores(threshold=0.7,\n",
    "                        price_increment=0.005, first_N=2, last_N=10, max_predictor=0.04, max_response=0.01,\n",
    "                        filter_score=None):\n",
    "    # 0 < threshold < 1, score which the pattern is considered good\n",
    "\n",
    "    trend = get_trend(prices, increment=price_increment)\n",
    "    \n",
    "    add_pattern_label(trend, max_return=max_predictor, increment_return=price_increment,\n",
    "                     label_type='predictor_label')\n",
    "    \n",
    "    add_pattern_label(trend, max_return=max_response, increment_return=price_increment,\n",
    "                     label_type='response_label')\n",
    "    \n",
    "    # HACKY, but can't think a better place to put this\n",
    "    # we don't care about 0 response\n",
    "    trend['response_label'].replace({0: np.nan}, inplace=True)\n",
    "    trend['response_label'].bfill(inplace=True)\n",
    "    \n",
    "    \n",
    "    best_scores = []\n",
    "    for i in range(first_N,last_N):\n",
    "        best_scores = best_scores + get_best_scores(trend, i, threshold=threshold)\n",
    "    \n",
    "    return combine_scores(best_scores, filter_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_APY(best_scores, ret, stop_loss):\n",
    "    # stop_loss: return in the other direction so we exit the position\n",
    "    if not best_scores:\n",
    "        return 0.\n",
    "    \n",
    "    num_trades = sum([i.num for i in best_scores])\n",
    "    freq = np.mean([i.freq for i in best_scores])\n",
    "    print(f'freq mean={freq}, num_trades={num_trades}')\n",
    "\n",
    "    APY = 0\n",
    "    for s in best_scores:\n",
    "        freq = s.freq\n",
    "        profit = freq  * ret\n",
    "        loss = stop_loss * (1-freq)\n",
    "        fee =  (2+ret)  * 0.0026\n",
    "        fee =  0.0026 + 0.0026* (1-freq) + 0.0016*freq\n",
    "\n",
    "        s.apy = (profit - loss - fee) * s.num\n",
    "        APY += s.apy# (profit - loss - fee) * s.num\n",
    "\n",
    "    # adjust for 1 year of trading\n",
    "    period = 365 / (prices.index[-1] - prices.index[0]).days\n",
    "    APY *= period\n",
    "    \n",
    "    best_scores.sort(reverse=True)\n",
    "    return APY\n",
    "\n",
    "# TODO: think as way to recover from loss other then stop loss.\n",
    "# How bad is just wait?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_even(ret, stop_loss, fee=0.0026) -> 'threshold':\n",
    "    return ((2+ret)  * fee + stop_loss) / (ret + stop_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6313"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_even(0.02, 0.020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(returns, best_scores):\n",
    "    returns = tuple(returns)\n",
    "    for s in best_scores:\n",
    "        seq, prediction = s.predictor, s.response\n",
    "        size_diff = len(seq) - len(returns)\n",
    "        seq = seq[max(size_diff, 0):]\n",
    "        r = returns[max(-size_diff, 0):]\n",
    "        assert len(r) == len(seq)\n",
    "        if r == seq:\n",
    "            return prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_score(x):\n",
    "    # True to remove\n",
    "    return -0.0099 < x.response < 0.0099 or x.num < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.8 s, sys: 291 ms, total: 51.1 s\n",
      "Wall time: 52.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_scores_005 = gen_multiple_scores(threshold=0.78, price_increment=0.005,\n",
    "                                      first_N=2, last_N=10, max_predictor=0.04, max_response=0.01,\n",
    "                                     filter_score=filter_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 48.3 ms, total: 13.3 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_scores_01 = gen_multiple_scores(threshold=0.78, price_increment=0.01,\n",
    "                                     first_N=2, last_N=10, max_predictor=0.04, max_response=0.01,\n",
    "                                     filter_score=filter_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq mean=0.82, num_trades=18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.030308035714285725"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_APY(best_scores_005, 0.01, stop_loss=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq mean=0.8096861471861473, num_trades=93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14319287743506495"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_APY(best_scores_01, 0.01, stop_loss=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 24, 28)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_scores_005), len(best_scores_01), len(combine_scores(best_scores_005 + best_scores_01,filter_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq mean=0.8081014223871368, num_trades=104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0836690267470626"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_APY(combine_scores(best_scores_005 + best_scores_01,filter_score), 0.01, stop_loss=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "best2 = (0, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for max_response=0.01, for max_predictor=0.01, for price_increment=0.01, break even =0.7613\n",
      "freq mean=0.7875861816094982, num_trades=137\n",
      "APY=0.1519447456125209\n",
      "for max_response=0.01, for max_predictor=0.01, for price_increment=0.02, break even =0.6313\n",
      "APY=0.0\n",
      "for max_response=0.01, for max_predictor=0.01, for price_increment=0.03, break even =0.5879666666666666\n",
      "APY=0.0\n",
      "for max_response=0.02, for max_predictor=0.01, for price_increment=0.01, break even =0.7613\n",
      "freq mean=0.7894736842105263, num_trades=14\n",
      "APY=0.015728618421052644\n",
      "for max_response=0.02, for max_predictor=0.01, for price_increment=0.02, break even =0.6313\n",
      "APY=0.0\n",
      "for max_response=0.02, for max_predictor=0.01, for price_increment=0.03, break even =0.5879666666666666\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.01, for price_increment=0.01, break even =0.7613\n",
      "freq mean=0.7894736842105263, num_trades=14\n",
      "APY=0.015728618421052644\n",
      "for max_response=0.03, for max_predictor=0.01, for price_increment=0.02, break even =0.6313\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.01, for price_increment=0.03, break even =0.5879666666666666\n",
      "APY=0.0\n",
      "for max_response=0.01, for max_predictor=0.02, for price_increment=0.01, break even =0.7613\n",
      "freq mean=0.8198757763975155, num_trades=28\n",
      "APY=0.04219604037267082\n",
      "for max_response=0.01, for max_predictor=0.02, for price_increment=0.02, break even =0.6313\n",
      "APY=0.0\n",
      "for max_response=0.01, for max_predictor=0.02, for price_increment=0.03, break even =0.5879666666666666\n",
      "APY=0.0\n",
      "for max_response=0.02, for max_predictor=0.02, for price_increment=0.01, break even =0.7613\n",
      "freq mean=0.8571428571428571, num_trades=11\n",
      "APY=0.025093749999999998\n",
      "for max_response=0.02, for max_predictor=0.02, for price_increment=0.02, break even =0.6313\n",
      "freq mean=0.6842105263157895, num_trades=12\n",
      "APY=0.027889567669172943\n",
      "for max_response=0.02, for max_predictor=0.02, for price_increment=0.03, break even =0.5879666666666666\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.02, for price_increment=0.01, break even =0.7613\n",
      "freq mean=0.8571428571428571, num_trades=11\n",
      "APY=0.025093749999999998\n",
      "for max_response=0.03, for max_predictor=0.02, for price_increment=0.02, break even =0.6313\n",
      "freq mean=0.6842105263157895, num_trades=12\n",
      "APY=0.027889567669172943\n",
      "for max_response=0.03, for max_predictor=0.02, for price_increment=0.03, break even =0.5879666666666666\n",
      "APY=0.0\n",
      "for max_response=0.01, for max_predictor=0.03, for price_increment=0.01, break even =0.7613\n",
      "freq mean=0.8025493025493026, num_trades=40\n",
      "APY=0.050488704004329026\n",
      "for max_response=0.01, for max_predictor=0.03, for price_increment=0.02, break even =0.6313\n",
      "APY=0.0\n",
      "for max_response=0.01, for max_predictor=0.03, for price_increment=0.03, break even =0.5879666666666666\n",
      "APY=0.0\n",
      "for max_response=0.02, for max_predictor=0.03, for price_increment=0.01, break even =0.7613\n",
      "freq mean=0.8571428571428571, num_trades=11\n",
      "APY=0.025093749999999998\n",
      "for max_response=0.02, for max_predictor=0.03, for price_increment=0.02, break even =0.6313\n",
      "freq mean=0.6842105263157895, num_trades=12\n",
      "APY=0.027889567669172943\n",
      "for max_response=0.02, for max_predictor=0.03, for price_increment=0.03, break even =0.5879666666666666\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.03, for price_increment=0.01, break even =0.7613\n",
      "freq mean=0.8571428571428571, num_trades=11\n",
      "APY=0.025093749999999998\n",
      "for max_response=0.03, for max_predictor=0.03, for price_increment=0.02, break even =0.6313\n",
      "freq mean=0.6842105263157895, num_trades=12\n",
      "APY=0.027889567669172943\n",
      "for max_response=0.03, for max_predictor=0.03, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "CPU times: user 4min, sys: 744 ms, total: 4min 1s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for max_predictor in (0.01, 0.02, 0.03):\n",
    "    for max_response in (0.01, 0.02, 0.03):\n",
    "        for price_increment in (0.01, 0.02, 0.03):\n",
    "            print(f'for max_response={max_response}, ', end='')\n",
    "            print(f'for max_predictor={max_predictor}, ', end='')\n",
    "            print(f'for price_increment={price_increment}, ', end='')\n",
    "            print(f'break even ={break_even(price_increment,price_increment)}')\n",
    "            APY = estimate_APY(gen_multiple_scores(threshold=break_even(price_increment,price_increment),\n",
    "                                                   price_increment=price_increment,\n",
    "                                                   first_N=2, last_N=10,\n",
    "                                                   max_predictor=max_predictor,\n",
    "                                                   max_response=max_response,\n",
    "                                                   filter_score=filter_score),\n",
    "                               ret=price_increment, stop_loss=price_increment)\n",
    "\n",
    "            print(f'APY={APY}')\n",
    "            if best2[0] < APY:\n",
    "                best2 = (APY, (max_response, max_predictor, price_increment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1.5219216398806623, (0.06, 0.06, 0.06)),\n",
       " (0.5318837185844435, (0.03, 0.03, 0.03)))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best, best2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = (0, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for max_response=0.03, for max_predictor=0.03, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "for max_response=0.03, for max_predictor=0.03, for price_increment=0.04, break even =0.5662999999999999\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.03, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.03, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.04, for max_predictor=0.03, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "for max_response=0.04, for max_predictor=0.03, for price_increment=0.04, break even =0.5662999999999999\n",
      "APY=0.0\n",
      "for max_response=0.04, for max_predictor=0.03, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.04, for max_predictor=0.03, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.05, for max_predictor=0.03, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "for max_response=0.05, for max_predictor=0.03, for price_increment=0.04, break even =0.5662999999999999\n",
      "APY=0.0\n",
      "for max_response=0.05, for max_predictor=0.03, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.05, for max_predictor=0.03, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.06, for max_predictor=0.03, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6379616874879861, num_trades=274\n",
      "APY=0.7963307022151733\n",
      "for max_response=0.06, for max_predictor=0.03, for price_increment=0.04, break even =0.5662999999999999\n",
      "APY=0.0\n",
      "for max_response=0.06, for max_predictor=0.03, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.06, for max_predictor=0.03, for price_increment=0.06, break even =0.5446333333333333\n",
      "freq mean=0.5619223659889094, num_trades=303\n",
      "APY=0.6893935090440989\n",
      "for max_response=0.03, for max_predictor=0.04, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "for max_response=0.03, for max_predictor=0.04, for price_increment=0.04, break even =0.5662999999999999\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.04, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.04, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.04, for max_predictor=0.04, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "for max_response=0.04, for max_predictor=0.04, for price_increment=0.04, break even =0.5662999999999999\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "APY=0.959830298580549\n",
      "for max_response=0.04, for max_predictor=0.04, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.04, for max_predictor=0.04, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.05, for max_predictor=0.04, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "for max_response=0.05, for max_predictor=0.04, for price_increment=0.04, break even =0.5662999999999999\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "APY=0.959830298580549\n",
      "for max_response=0.05, for max_predictor=0.04, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.05, for max_predictor=0.04, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.06, for max_predictor=0.04, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6379616874879861, num_trades=274\n",
      "APY=0.7963307022151733\n",
      "for max_response=0.06, for max_predictor=0.04, for price_increment=0.04, break even =0.5662999999999999\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "APY=0.959830298580549\n",
      "for max_response=0.06, for max_predictor=0.04, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.06, for max_predictor=0.04, for price_increment=0.06, break even =0.5446333333333333\n",
      "freq mean=0.5619223659889094, num_trades=303\n",
      "APY=0.6893935090440989\n",
      "for max_response=0.03, for max_predictor=0.05, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "for max_response=0.03, for max_predictor=0.05, for price_increment=0.04, break even =0.5662999999999999\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.05, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.05, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.04, for max_predictor=0.05, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "for max_response=0.04, for max_predictor=0.05, for price_increment=0.04, break even =0.5662999999999999\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "APY=0.959830298580549\n",
      "for max_response=0.04, for max_predictor=0.05, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.04, for max_predictor=0.05, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.05, for max_predictor=0.05, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "APY=0.5318837185844435\n",
      "for max_response=0.05, for max_predictor=0.05, for price_increment=0.04, break even =0.5662999999999999\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "APY=0.959830298580549\n",
      "for max_response=0.05, for max_predictor=0.05, for price_increment=0.05, break even =0.5533\n",
      "freq mean=0.585956822319927, num_trades=312\n",
      "APY=1.0338656560058024\n",
      "for max_response=0.05, for max_predictor=0.05, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.06, for max_predictor=0.05, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6379616874879861, num_trades=274\n",
      "APY=0.7963307022151733\n",
      "for max_response=0.06, for max_predictor=0.05, for price_increment=0.04, break even =0.5662999999999999\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "APY=0.959830298580549\n",
      "for max_response=0.06, for max_predictor=0.05, for price_increment=0.05, break even =0.5533\n",
      "freq mean=0.585956822319927, num_trades=312\n",
      "APY=1.0338656560058024\n",
      "for max_response=0.06, for max_predictor=0.05, for price_increment=0.06, break even =0.5446333333333333\n",
      "freq mean=0.5619223659889094, num_trades=303\n",
      "APY=0.6893935090440989\n",
      "for max_response=0.03, for max_predictor=0.06, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6219626666675188, num_trades=428\n",
      "APY=0.7900798944693267\n",
      "for max_response=0.03, for max_predictor=0.06, for price_increment=0.04, break even =0.5662999999999999\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.06, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.03, for max_predictor=0.06, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.04, for max_predictor=0.06, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6219626666675188, num_trades=428\n",
      "APY=0.7900798944693267\n",
      "for max_response=0.04, for max_predictor=0.06, for price_increment=0.04, break even =0.5662999999999999\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "APY=0.959830298580549\n",
      "for max_response=0.04, for max_predictor=0.06, for price_increment=0.05, break even =0.5533\n",
      "APY=0.0\n",
      "for max_response=0.04, for max_predictor=0.06, for price_increment=0.06, break even =0.5446333333333333\n",
      "APY=0.0\n",
      "for max_response=0.05, for max_predictor=0.06, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6219626666675188, num_trades=428\n",
      "APY=0.7900798944693267\n",
      "for max_response=0.05, for max_predictor=0.06, for price_increment=0.04, break even =0.5662999999999999\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "APY=0.959830298580549\n",
      "for max_response=0.05, for max_predictor=0.06, for price_increment=0.05, break even =0.5533\n",
      "freq mean=0.585956822319927, num_trades=312\n",
      "APY=1.0338656560058024\n",
      "for max_response=0.05, for max_predictor=0.06, for price_increment=0.06, break even =0.5446333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APY=0.0\n",
      "for max_response=0.06, for max_predictor=0.06, for price_increment=0.03, break even =0.5879666666666666\n",
      "freq mean=0.6146898067615227, num_trades=355\n",
      "APY=0.541334781036265\n",
      "for max_response=0.06, for max_predictor=0.06, for price_increment=0.04, break even =0.5662999999999999\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "APY=0.959830298580549\n",
      "for max_response=0.06, for max_predictor=0.06, for price_increment=0.05, break even =0.5533\n",
      "freq mean=0.585956822319927, num_trades=312\n",
      "APY=1.0338656560058024\n",
      "for max_response=0.06, for max_predictor=0.06, for price_increment=0.06, break even =0.5446333333333333\n",
      "freq mean=0.5994335844164287, num_trades=289\n",
      "APY=1.5219216398806623\n",
      "CPU times: user 1min 39s, sys: 426 ms, total: 1min 40s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for max_predictor in (0.03, 0.04, 0.05, 0.06):\n",
    "    for max_response in (0.03, 0.04, 0.05, 0.06):\n",
    "        for price_increment in (0.03, 0.04, 0.05, 0.06):\n",
    "            print(f'for max_response={max_response}, ', end='')\n",
    "            print(f'for max_predictor={max_predictor}, ', end='')\n",
    "            print(f'for price_increment={price_increment}, ', end='')\n",
    "            print(f'break even ={break_even(price_increment,price_increment)}')\n",
    "            APY = estimate_APY(gen_multiple_scores(threshold=break_even(price_increment,price_increment),\n",
    "                                                   price_increment=price_increment,\n",
    "                                                   first_N=2, last_N=10,\n",
    "                                                   max_predictor=max_predictor,\n",
    "                                                   max_response=max_response,\n",
    "                                                   filter_score=filter_score),\n",
    "                               ret=price_increment, stop_loss=price_increment)\n",
    "\n",
    "            print(f'APY={APY}')\n",
    "            if APY > best[0]:\n",
    "                best = (APY, (max_predictor,max_response,price_increment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4129686943229672, (0.03, 0.06, 0.03))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-70-8e4ca28dde34>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-70-8e4ca28dde34>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for max_response=0.03, for max_predictor=0.06, for price_increment=0.03\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for max_response=0.03, for max_predictor=0.06, for price_increment=0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_response=0.04\n",
    "max_predictor=0.04\n",
    "price_increment=0.04\n",
    "best_score_max = gen_multiple_scores(threshold=break_even(price_increment,price_increment),\n",
    "                                     price_increment=price_increment,\n",
    "                                     first_N=2, last_N=10,\n",
    "                                     max_predictor=max_predictor,\n",
    "                                     max_response=max_response,\n",
    "                                     filter_score=filter_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Score(apy=0.0, freq=0.62, num=47,predictor=(0.04, 0.0, -0.04, 0.0, 0.04), response=0.04),\n",
       " Score(apy=0.0, freq=0.62, num=12,predictor=(-0.04, 0.0, -0.04, 0.0, -0.04, 0.0, 0.04), response=-0.04),\n",
       " Score(apy=0.0, freq=0.6, num=146,predictor=(-0.04,), response=0.04),\n",
       " Score(apy=0.0, freq=0.59, num=71,predictor=(-0.04, 0.0, 0.04, 0.0), response=0.04),\n",
       " Score(apy=0.0, freq=0.58, num=20,predictor=(0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04), response=-0.04),\n",
       " Score(apy=0.0, freq=0.57, num=127,predictor=(-0.04, 0.0), response=0.04),\n",
       " Score(apy=0.0, freq=0.57, num=19,predictor=(0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0), response=-0.04),\n",
       " Score(apy=0.0, freq=0.57, num=19,predictor=(-0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0), response=0.04),\n",
       " Score(apy=0.0, freq=0.57, num=19,predictor=(-0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04), response=0.04)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq mean=0.5877777777777777, num_trades=480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9699793526785706"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_APY(best_score_max, ret=price_increment, stop_loss=price_increment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "freq mean=0.7875861816094982, num_trades=137\n",
      "0.1519447456125209\n",
      "0.02\n",
      "freq mean=0.6842105263157895, num_trades=12\n",
      "0.027889567669172943\n",
      "0.03\n",
      "freq mean=0.6042596304502499, num_trades=487\n",
      "0.5318837185844435\n",
      "0.04\n",
      "freq mean=0.5885087673206054, num_trades=480\n",
      "0.959830298580549\n",
      "0.05\n",
      "freq mean=0.585956822319927, num_trades=312\n",
      "1.0338656560058024\n",
      "0.06\n",
      "freq mean=0.5994335844164287, num_trades=289\n",
      "1.5219216398806623\n",
      "0.07\n",
      "freq mean=0.5763481674842473, num_trades=209\n",
      "1.008008706902492\n",
      "0.08\n",
      "freq mean=0.616039682969403, num_trades=152\n",
      "1.6279756493506503\n",
      "0.09\n",
      "freq mean=0.599462068938813, num_trades=138\n",
      "1.764434173510079\n",
      "0.1\n",
      "freq mean=0.5931308275058275, num_trades=122\n",
      "1.3572879508187126\n"
     ]
    }
   ],
   "source": [
    "best_inc = {}\n",
    "for i in (0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1):\n",
    "    print(i)\n",
    "    max_response=i\n",
    "    max_predictor=i\n",
    "    price_increment=i\n",
    "    best_score_max = gen_multiple_scores(threshold=break_even(price_increment,price_increment),\n",
    "                                 price_increment=price_increment,\n",
    "                                 first_N=2, last_N=10,\n",
    "                                 max_predictor=max_predictor,\n",
    "                                 max_response=max_response,\n",
    "                                 filter_score=filter_score)   \n",
    "    best_inc[i] = best_score_max\n",
    "    print(estimate_APY(best_score_max, i, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.01: [Score(freq=0.7948717948717948, num=30, predictor=(0.0, 0.01, -0.01, 0.0, -0.01), response=0.01, apy=0.04476923076923076),\n",
       "  Score(freq=0.8421052631578947, num=15, predictor=(-0.01, 0.0, -0.01, 0.0, -0.01, 0.0, -0.01, 0.01), response=0.01, apy=0.037263157894736824),\n",
       "  Score(freq=0.78125, num=24, predictor=(-0.01, 0.0, -0.01, 0.0, -0.01, 0.01, 0.0), response=0.01, apy=0.028949999999999997),\n",
       "  Score(freq=0.7894736842105263, num=14, predictor=(0.01, -0.01, 0.01), response=-0.01, apy=0.01930526315789475),\n",
       "  Score(freq=0.7727272727272727, num=16, predictor=(0.0, 0.01, -0.01, 0.0, 0.01, 0.0, 0.01), response=-0.01, apy=0.01643636363636365),\n",
       "  Score(freq=0.7777777777777778, num=13, predictor=(0.01, 0.0, -0.01, 0.01, 0.0, 0.01, 0.0, -0.01), response=0.01, apy=0.014733333333333345),\n",
       "  Score(freq=0.7777777777777778, num=13, predictor=(-0.01, 0.0, 0.01, -0.01, 0.0, -0.01, 0.0), response=0.01, apy=0.014733333333333345),\n",
       "  Score(freq=0.7647058823529411, num=12, predictor=(-0.01, 0.0, 0.01, -0.01, 0.0, 0.01, 0.0), response=0.01, apy=0.010305882352941172)],\n",
       " 0.02: [Score(freq=0.6842105263157895, num=12, predictor=(-0.02, 0.0, -0.02, 0.02, 0.0), response=0.02, apy=0.03423157894736843)],\n",
       " 0.03: [Score(freq=0.6, num=95, predictor=(-0.03, 0.0, -0.03), response=0.03, apy=0.13299999999999984),\n",
       "  Score(freq=0.6428571428571429, num=26, predictor=(-0.03, 0.0, 0.03, 0.0, 0.03, 0.0, -0.03, 0.0), response=0.03, apy=0.10437142857142868),\n",
       "  Score(freq=0.59, num=117, predictor=(0.0, 0.03, 0.0, -0.03), response=0.03, apy=0.09242999999999968),\n",
       "  Score(freq=0.6388888888888888, num=22, predictor=(-0.03, 0.0, 0.03, 0.0, -0.03, 0.0, -0.03, 0.0), response=0.03, apy=0.08298888888888885),\n",
       "  Score(freq=0.594059405940594, num=59, predictor=(-0.03, 0.0, 0.03, 0.0, 0.03, 0.0), response=0.03, apy=0.0612198019801979),\n",
       "  Score(freq=0.5934065934065934, num=53, predictor=(-0.03, 0.0, 0.03, 0.0, -0.03, 0.0), response=0.03, apy=0.052883516483516406),\n",
       "  Score(freq=0.6, num=35, predictor=(0.0, -0.03, 0.0, -0.03, 0.0, -0.03, 0.0), response=0.03, apy=0.048999999999999946),\n",
       "  Score(freq=0.5932203389830508, num=34, predictor=(0.03, 0.0, -0.03, 0.0, 0.03, 0.0, 0.03), response=0.03, apy=0.033538983050847335),\n",
       "  Score(freq=0.5901639344262295, num=35, predictor=(-0.03, 0.0, 0.03, 0.0, 0.03, 0.0, 0.03), response=-0.03, apy=0.027999999999999983),\n",
       "  Score(freq=0.6, num=11, predictor=(0.0, -0.03, 0.03, 0.0), response=0.03, apy=0.015399999999999983)],\n",
       " 0.04: [Score(freq=0.6, num=146, predictor=(-0.04,), response=0.04, apy=0.49640000000000006),\n",
       "  Score(freq=0.6233766233766234, num=47, predictor=(0.04, 0.0, -0.04, 0.0, 0.04), response=0.04, apy=0.24879480519480515),\n",
       "  Score(freq=0.5901639344262295, num=71, predictor=(-0.04, 0.0, 0.04, 0.0), response=0.04, apy=0.18483278688524585),\n",
       "  Score(freq=0.5663716814159292, num=127, predictor=(-0.04, 0.0), response=0.04, apy=0.08586548672566376),\n",
       "  Score(freq=0.6190476190476191, num=12, predictor=(-0.04, 0.0, -0.04, 0.0, -0.04, 0.0, 0.04), response=-0.04, apy=0.059314285714285736),\n",
       "  Score(freq=0.5833333333333334, num=20, predictor=(0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04), response=-0.04, apy=0.04100000000000003),\n",
       "  Score(freq=0.5714285714285714, num=19, predictor=(0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0), response=-0.04, apy=0.02062857142857142),\n",
       "  Score(freq=0.5714285714285714, num=19, predictor=(-0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04, 0.0), response=0.04, apy=0.02062857142857142),\n",
       "  Score(freq=0.5714285714285714, num=19, predictor=(-0.04, 0.0, 0.04, 0.0, 0.04, 0.0, 0.04), response=0.04, apy=0.02062857142857142)],\n",
       " 0.05: [Score(freq=0.6103896103896104, num=93, predictor=(-0.05,), response=0.05, apy=0.5997896103896101),\n",
       "  Score(freq=0.5921052631578947, num=44, predictor=(-0.05, 0.0, 0.05, 0.0), response=0.05, apy=0.20251578947368395),\n",
       "  Score(freq=0.5683453237410072, num=78, predictor=(-0.05, 0.0), response=0.05, apy=0.17182446043165478),\n",
       "  Score(freq=0.6086956521739131, num=13, predictor=(-0.05, 0.0, 0.05, 0.0, 0.05, 0.0, 0.05, 0.0), response=0.05, apy=0.08161739130434792),\n",
       "  Score(freq=0.6086956521739131, num=13, predictor=(-0.05, 0.0, 0.05, 0.0, 0.05, 0.0, 0.05), response=0.05, apy=0.08161739130434792),\n",
       "  Score(freq=0.5625, num=44, predictor=(-0.05, 0.0, 0.05), response=0.05, apy=0.07094999999999993),\n",
       "  Score(freq=0.5769230769230769, num=14, predictor=(0.05, 0.0, 0.05, 0.0, 0.05, 0.0, 0.05), response=-0.05, apy=0.042969230769230676),\n",
       "  Score(freq=0.56, num=13, predictor=(0.05, 0.0, 0.05, 0.0, 0.05, 0.0, 0.05, 0.0), response=-0.05, apy=0.01768000000000007)],\n",
       " 0.06: [Score(freq=0.6504065040650406, num=79, predictor=(-0.06,), response=0.06, apy=1.0664357723577236),\n",
       "  Score(freq=0.5610687022900763, num=146, predictor=(0.0,), response=0.06, apy=0.39263969465648846),\n",
       "  Score(freq=0.6666666666666666, num=11, predictor=(-0.06, 0.0, 0.06, 0.0, -0.06, 0.0, 0.06), response=0.06, apy=0.17013333333333325),\n",
       "  Score(freq=0.6, num=11, predictor=(0.06, 0.0, 0.06, 0.0, 0.06, 0.0, 0.06), response=-0.06, apy=0.08139999999999997),\n",
       "  Score(freq=0.5909090909090909, num=12, predictor=(0.06, 0.0, 0.06, 0.0, -0.06, 0.0, 0.06), response=-0.06, apy=0.07560000000000001),\n",
       "  Score(freq=0.5714285714285714, num=11, predictor=(-0.06, 0.0, 0.06, 0.0, 0.06, 0.0, 0.06), response=0.06, apy=0.043371428571428526),\n",
       "  Score(freq=0.5555555555555556, num=19, predictor=(-0.06, 0.0, 0.06, 0.0, 0.06), response=0.06, apy=0.03842222222222225)],\n",
       " 0.07: [Score(freq=0.5786516853932584, num=102, predictor=(0.0,), response=0.07, apy=0.6517685393258424),\n",
       "  Score(freq=0.6049382716049383, num=48, predictor=(-0.07,), response=0.07, apy=0.4846222222222224),\n",
       "  Score(freq=0.5454545454545454, num=59, predictor=(0.07,), response=0.07, apy=0.1008363636363636)],\n",
       " 0.08: [Score(freq=0.6515151515151515, num=42, predictor=(-0.08,), response=0.08, apy=0.8271454545454546),\n",
       "  Score(freq=0.589041095890411, num=85, predictor=(0.0,), response=0.08, apy=0.8190273972602747),\n",
       "  Score(freq=0.6521739130434783, num=14, predictor=(0.08, 0.0, -0.08, 0.0, 0.08), response=0.08, apy=0.27720000000000006),\n",
       "  Score(freq=0.5714285714285714, num=11, predictor=(-0.08, 0.0, 0.08, 0.0, 0.08), response=0.08, apy=0.07479999999999999)],\n",
       " 0.09: [Score(freq=0.6785714285714286, num=37, predictor=(-0.09,), response=0.09, apy=1.0219928571428576),\n",
       "  Score(freq=0.5968992248062015, num=76, predictor=(0.0,), response=0.09, apy=0.9757457364341078),\n",
       "  Score(freq=0.5769230769230769, num=14, predictor=(0.09, 0.0, -0.09, 0.0, 0.09), response=0.09, apy=0.12912307692307684),\n",
       "  Score(freq=0.5454545454545454, num=11, predictor=(0.09, 0.0, 0.09, 0.0, 0.09), response=0.09, apy=0.038799999999999966)],\n",
       " 0.1: [Score(freq=0.5961538461538461, num=61, predictor=(0.0,), response=0.1, apy=0.8922423076923078),\n",
       "  Score(freq=0.6363636363636364, num=27, predictor=(-0.1,), response=0.1, apy=0.6131454545454547),\n",
       "  Score(freq=0.546875, num=34, predictor=(0.1,), response=0.1, apy=0.16054374999999982)]}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtesting import Backtest, Strategy\n",
    "from backtesting.lib import crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtesting.test import SMA, GOOG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Trades']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.iloc[:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from backtesting.test import SMA, GOOG\n",
    "\n",
    "\n",
    "class SmaCross(Strategy):\n",
    "    def init(self):\n",
    "        price = self.data.Close\n",
    "        self.ma1 = self.I(SMA, price, 10)\n",
    "        self.ma2 = self.I(SMA, price, 20)\n",
    "\n",
    "    def next(self):\n",
    "        if crossover(self.ma1, self.ma2):\n",
    "            self.buy()\n",
    "        elif crossover(self.ma2, self.ma1):\n",
    "            self.sell()\n",
    "\n",
    "\n",
    "bt = Backtest(GOOG, SmaCross, commission=.002,\n",
    "              exclusive_orders=True)\n",
    "stats = bt.run()\n",
    "bt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Backtest.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kraken download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krakenex\n",
    "from pykrakenapi import KrakenAPI\n",
    "api = krakenex.API()\n",
    "k = KrakenAPI(api)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(pd.Timestamp('20210101 00:02:00').timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(1548111600 * 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.get_ohlc_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "start = '2021-03-31 23:52:00'\n",
    "end = '2021-05-30 23:00:00'\n",
    "\n",
    "start = int(pd.Timestamp(start).timestamp()) * 1e9\n",
    "end = int(pd.Timestamp(end).timestamp()) * 1e9\n",
    "last = start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "while True:\n",
    "    resp = requests.get(f'https://api.kraken.com/0/public/Trades?pair=BTCUSD&since={last}')\n",
    "    r = resp.json()\n",
    "    if r['error']:\n",
    "        raise Exception(r['error'])\n",
    "    r = r['result']\n",
    "    last = r['last']\n",
    "    final = final + r['XXBTZUSD']\n",
    "    print(f'final is {pd.Timestamp(int(last))}')\n",
    "    sleep(2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(1622431239065055006)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
